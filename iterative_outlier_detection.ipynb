{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a1430a8-2bc8-4e6f-b539-f8442ba616cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import model_tools\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import iqr\n",
    "\n",
    "folder = os.path.join('H:','My Drive','PROJECTS','PSI XAS (2022-2025)','XAS Tourmaline Fe predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1277d5-92c2-4d91-8a28-673328c53f54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c59cc11-ff44-4960-a363-2704ad24fc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "variable = 'percent_ferric'\n",
    "method = 'PLS'\n",
    "threshold_type = ['percent_samples', 'rmse'] # max_iter # percent_diff\n",
    "max_iter = 6\n",
    "percent_diff_threshold = 0.1\n",
    "rmse_threshold = 7\n",
    "percent_samples_threshold = 1/3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848e58de-f261-4ec8-8160-59451914359e",
   "metadata": {},
   "source": [
    "### Call variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c59fe112-1a35-4747-a3a3-56c94b5be251",
   "metadata": {},
   "outputs": [],
   "source": [
    "#maximum number of components for PLS\n",
    "max_components = 30\n",
    "# number of values to test for LASSO, Ridge, ElasticNet, SVR\n",
    "num_params = 30\n",
    "# polynomial degree for SVR and kernel PCR\n",
    "poly_deg = 2\n",
    "# maximum number of neighbors for kNN\n",
    "max_neighbors = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22aa2e2f-e89f-4b0f-a139-ab81fa2f2ce0",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a83a3af-776f-43a7-9c1f-8164cee3a7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_results(formatted_data, variable, fold_col, test_fold=None):\n",
    "\n",
    "    global max_components, num_params, poly_deg, max_neighbors\n",
    "    \n",
    "    # get data\n",
    "    data_dict, min_samples = formatted_data.make_data_dict(variable, fold_col, test_fold)\n",
    "\n",
    "    # initiate modelling class with data dictionary\n",
    "    modelling = model_tools.Model(data_dict, hide_progress=True)\n",
    "\n",
    "    reg_cv_dict = {\n",
    "    'PLS':{'func':modelling.run_PLS,\n",
    "           'args':max_components},\n",
    "    'LASSO':{'func':modelling.run_LASSO,\n",
    "             'args':num_params},\n",
    "    'Ridge':{'func':modelling.run_Ridge,\n",
    "             'args':num_params},\n",
    "    'ElasticNet':{'func':modelling.run_ElasticNet,\n",
    "                  'args':num_params},\n",
    "    'SVR-lin':{'func':modelling.run_SVR_linear,\n",
    "               'args':num_params},\n",
    "    'SVR-py':{'func':modelling.run_SVR_poly,\n",
    "              'args':(num_params, poly_deg)},\n",
    "    'PCR-lin':{'func':modelling.run_PCR_linear,\n",
    "           'args':None},\n",
    "    'PCR-py':{'func':modelling.run_PCR_poly,\n",
    "             'args':poly_deg},\n",
    "    'OMP':{'func':modelling.run_OMP,\n",
    "           'args':None},\n",
    "    'RF':{'func':modelling.run_RF,\n",
    "           'args':None},\n",
    "    'GBR':{'func':modelling.run_GBR,\n",
    "           'args':None},\n",
    "    'OLS':{'func':modelling.run_OLS,\n",
    "           'args':None},\n",
    "    'kNN':{'func':modelling.run_kNN,\n",
    "           'args':max_neighbors}\n",
    "    }\n",
    "    \n",
    "    # get RMSECV\n",
    "    if type(reg_cv_dict[method]['args']) == int: # if has arguments...\n",
    "        param, rmsecv, model = reg_cv_dict[method]['func'](reg_cv_dict[method]['args'])\n",
    "    elif reg_cv_dict[method]['args']:\n",
    "        param, rmsecv, model = reg_cv_dict[method]['func'](*reg_cv_dict[method]['args'])\n",
    "    else:\n",
    "        param, rmsecv, model = reg_cv_dict[method]['func']()\n",
    "\n",
    "    # prep data for training\n",
    "    if test_fold is not None:\n",
    "        train_names, X_train, y_train, test_names, X_test, y_test = form.format_spectra_meta(variable, fold_col, test_fold)\n",
    "    else:\n",
    "        train_names, X_train, y_train = form.format_spectra_meta(variable, fold_col)                                                          \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # get RMSE-C\n",
    "    train_preds = model.predict(X_train)\n",
    "    train_pred_true = pd.DataFrame({\n",
    "        'pkey' : train_names,\n",
    "        'actual' : y_train.flatten().tolist(),\n",
    "        'pred' : train_preds.flatten().tolist()\n",
    "    })\n",
    "    rmsec = sqrt(mean_squared_error(\n",
    "        train_pred_true['actual'], \n",
    "        train_pred_true['pred'])\n",
    "                )\n",
    "    r2_train = model.score(X_train,y_train)\n",
    "\n",
    "    if test_fold is not None:\n",
    "        # get test value\n",
    "        test_preds = model.predict(X_test)\n",
    "        test_pred_true = pd.DataFrame({\n",
    "            'pkey' : test_names,\n",
    "            'actual' : y_test.flatten().tolist(),\n",
    "            'pred' : test_preds.flatten().tolist()\n",
    "        })\n",
    "        rmsep = sqrt(mean_squared_error(\n",
    "            test_pred_true['actual'], \n",
    "            test_pred_true['pred']\n",
    "        ))\n",
    "        # can't do percentage due to all the zeroes\n",
    "        # test R2 wasn't helpeful because only one point\n",
    "    \n",
    "        return rmsecv, rmsec, r2_train, rmsep\n",
    "    else:\n",
    "        return rmsecv, rmsec, r2_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4725f61-a237-4bfd-b7ff-1e957fd1a6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_plot(x, y, main_df, outlier_df=None):\n",
    "\n",
    "    if outlier_df is not None:\n",
    "        # remove common samples\n",
    "        main_df = main_df[~main_df.Sample_Name.isin(outlier_df.Sample_Name)].reset_index(drop=True)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    ax.scatter(main_df[x], main_df[y], color='black')\n",
    "    if outlier_df is not None:\n",
    "        ax.scatter(outlier_df[x], outlier_df[y], color='darkred', label='Potential outliers')\n",
    "        for idx, row in outlier_df.iterrows():\n",
    "            ax.annotate(idx, (row[x], row[y]))\n",
    "        plt.legend()\n",
    "    plt.ylabel(y)\n",
    "    plt.xlabel(x)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "770379df-cb63-4b0d-b33f-1f8ef08ee59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_outlier(df, train_col, test_col):\n",
    "    \n",
    "    # easiest case - one has the lowest train and highest test\n",
    "    worst_train = df.sort_values(train_col, ignore_index=True)['Sample_Name'][0]\n",
    "    worst_test = df.sort_values(test_col, ascending=False, ignore_index=True)['Sample_Name'][0]\n",
    "    if worst_train == worst_test:\n",
    "        outlier = worst_train\n",
    "    \n",
    "    # then, use the IQR to help\n",
    "    else:\n",
    "        # want low RMSE\n",
    "        train_RMSE_lower = np.percentile(df[train_col], 25)\n",
    "        # want high RMSEP\n",
    "        test_RMSE_upper = np.percentile(df[test_col], 75)\n",
    "    \n",
    "        # samples outside the custom IQR\n",
    "        potential_outliers = df[\n",
    "            (result_df[train_col] < train_RMSE_lower)&\n",
    "            (result_df[test_col] > test_RMSE_upper)\n",
    "        ].reset_index(drop=True).copy()\n",
    "        \n",
    "        # if more than one, choose that with the lowest train RMSE\n",
    "        if len(potential_outliers)>1:\n",
    "            outlier = potential_outliers.sort_values(train_col, ignore_index=True)['Sample_Name'][0]\n",
    "        elif len(potential_outliers)==0:\n",
    "            print('Halting procedure: No obvious outliers found')\n",
    "            # this implies that the values are stable?\n",
    "            data_plot(train_col, test_col, df)\n",
    "            outlier = False\n",
    "        else:\n",
    "            outlier = potential_outliers['Sample_Name'][0]\n",
    "    return outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba734e9-8d87-4c8d-95df-83a1ca272908",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfeffd18-22c0-4411-b398-50d1990632b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "all_spectra = pd.read_csv(os.path.join(folder, 'data', 'fully_aligned_spectra_all.csv'))\n",
    "all_metadata = pd.read_csv(os.path.join(folder, 'data', 'metadata_all.csv'))\n",
    "# sort to make sure the same\n",
    "if any(all_spectra.columns[1:] != list(all_metadata.pkey)):\n",
    "    print('Sorting to match')\n",
    "    vals = list(all_metadata.pkey)\n",
    "    vals.sort()\n",
    "    meta.sort_values('pkey', ignore_index=True, inplace=True)\n",
    "    vals.insert(0,'wave')\n",
    "    all_spectra = all_spectra[vals]\n",
    "\n",
    "# LOO stratification\n",
    "fold_df = pd.DataFrame(all_metadata.Sample_Name.unique()).reset_index()\n",
    "fold_df.columns = ['Folds','Sample_Name']\n",
    "all_metadata = all_metadata.merge(fold_df, how='left')\n",
    "\n",
    "# key\n",
    "sample_dict = dict(zip(fold_df.Folds, fold_df.Sample_Name))\n",
    "var_dict = dict(zip(all_metadata.Sample_Name, all_metadata[variable]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af30c6d-0a4d-4bdb-86e9-8aff51a92ea8",
   "metadata": {},
   "source": [
    "#### Threshold for this work\n",
    "Either 1/3 of samples are outliers, or the RMSE is below 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dbbb9d-1d62-48d8-b567-6d21c824d328",
   "metadata": {},
   "source": [
    "### Run procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04e2a30-3756-4920-8d60-9d7d738da78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding outlier #1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0f0f1aacf974821b95f08c6d7927a3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sample:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spectra = all_spectra.copy()\n",
    "meta = all_metadata.copy()\n",
    "\n",
    "train_col = 'avg_train_RMSE'\n",
    "test_col = 'RMSEP'\n",
    "to_continue = True\n",
    "count=1\n",
    "outlier_list = []\n",
    "rmse_list = []\n",
    "diff_list = []\n",
    "per_diff_list = []\n",
    "\n",
    "# only define once\n",
    "if 'percent_samples' in threshold_type:\n",
    "    max_n_outliers = int(percent_samples_threshold * all_metadata.Sample_Name.nunique())\n",
    "\n",
    "while to_continue is True:\n",
    "    # prep data formatting\n",
    "    form = model_tools.Format(spectra, meta)\n",
    "    fold_col = form.get_fold_col(variable)\n",
    "\n",
    "    # get original RMSEC\n",
    "    if count==1:\n",
    "        rmsecv, rmsec, r2_train = get_model_results(form, variable, fold_col)\n",
    "        rmse = round((rmsecv + rmsec)/2,2)\n",
    "        outlier_list.append('no outliers removed')\n",
    "        rmse_list.append(rmse)\n",
    "        diff_list.append(np.nan)\n",
    "        per_diff_list.append(np.nan)\n",
    "\n",
    "    print(f'Finding outlier #{count}')\n",
    "    result_data = []\n",
    "    for test_fold in tqdm(list(meta.Folds.unique()), desc='Sample', leave=False):\n",
    "        sample = sample_dict[test_fold]\n",
    "        # make model\n",
    "        rmsecv, rmsec, r2_train, rmsep = get_model_results(form, variable, fold_col, test_fold)\n",
    "        results = [test_fold, sample, rmsecv, rmsec, r2_train, rmsep]\n",
    "        result_data.append(results)\n",
    "    result_cols = ['Fold','Sample_Name','RMSECV','RMSEC','R2_train','RMSEP']\n",
    "    result_df = pd.DataFrame(result_data, columns=result_cols)\n",
    "    result_df['avg_train_RMSE'] = result_df[['RMSEC','RMSECV']].mean(axis=1)\n",
    "    \n",
    "    # find outlier\n",
    "    outlier = identify_outlier(result_df, train_col, test_col)   \n",
    "    to_continue = False if outlier is False else to_continue # exit if needed\n",
    "    if outlier is not False:\n",
    "        outlier_list.append(outlier)\n",
    "        # save that value as the train RMSE to match to\n",
    "        current_rmse = result_df[result_df.Sample_Name==outlier][train_col].values[0]\n",
    "        rmse_list.append(current_rmse)\n",
    "\n",
    "        # find difference between this and the last value\n",
    "        last_rmse = rmse_list[-2]\n",
    "        diff = current_rmse - last_rmse\n",
    "        per_diff = round((diff/last_rmse)*100,1)\n",
    "        diff_list.append(diff)\n",
    "        per_diff_list.append(per_diff)\n",
    "        \n",
    "        ### define some minimum difference threshold to stop at\n",
    "        ## if abs(per_diff) < some threshold, to_continue = False\n",
    "    \n",
    "        # remove outlier and prep for next iteration\n",
    "        meta = meta[meta.Sample_Name!=outlier].reset_index(drop=True)\n",
    "        cols = list(meta.pkey)\n",
    "        cols.insert(0,'wave')\n",
    "        spectra = spectra[cols]\n",
    "    \n",
    "        count+=1\n",
    "\n",
    "        # see if passes a breakage threshold\n",
    "        if 'max_iter' in threshold_type:\n",
    "            if count >= max_iter:\n",
    "                print('Halting procedure: Reached maximum number of iterations')\n",
    "                to_continue = False\n",
    "        if 'rmse' in threshold_type:\n",
    "            if current_rmse <= rmse_threshold:\n",
    "                if to_continue is True:\n",
    "                    print(f'Halting procedure: Current training RMSE of {round(current_rmse,2)} below threshold of {rmse_threshold}')\n",
    "                to_continue = False\n",
    "        if 'percent_diff' in threshold_type:\n",
    "            if per_diff <= percent_diff_threshold:\n",
    "                if to_continue is True:\n",
    "                    print(f'Halting procedure: Training RMSE after last outlier removal has a difference to the previous model below the threshold of {percent_diff_threshold}%')\n",
    "                to_continue = False\n",
    "        if 'percent_samples' in threshold_type:\n",
    "            n_outliers = count-1\n",
    "            # don't subtract 1 because checking to see if a new outlier would push it over the threshold\n",
    "            if n_outliers == max_n_outliers:\n",
    "                if to_continue is True:\n",
    "                    print(f'Halting procedure: Reached the maximum of {n_outliers-1} outliers, which was defined as {round(percent_samples_threshold*100,2)}% of all samples')\n",
    "                to_continue = False\n",
    "    \n",
    "# collate results\n",
    "outlier_result_df = pd.DataFrame({\n",
    "    'outlier':outlier_list,\n",
    "    'avg_train_RMSE':rmse_list,\n",
    "    'difference':diff_list,\n",
    "    'percent_difference':per_diff_list\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286a5552-e3b3-43c1-a134-b770b23847e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show results\n",
    "fig, ax = plt.subplots(nrows=2, figsize=(6,4), sharex=True)\n",
    "# actual values\n",
    "ax[0].plot(outlier_result_df['outlier'], outlier_result_df['avg_train_RMSE'])\n",
    "ax[0].scatter(outlier_result_df['outlier'], outlier_result_df['avg_train_RMSE'])\n",
    "ax[0].set_xticks(ticks=outlier_result_df['outlier'], labels=[])\n",
    "ax[0].set_ylabel(train_col)\n",
    "\n",
    "# difference\n",
    "ax[1].plot(outlier_result_df['outlier'], outlier_result_df['percent_difference'])\n",
    "ax[1].scatter(outlier_result_df['outlier'], outlier_result_df['percent_difference'])\n",
    "ax[1].set_ylabel('percent difference')\n",
    "ax[1].set_xticks(ticks=outlier_result_df['outlier'], labels=outlier_result_df['outlier'], rotation=90)\n",
    "ax[1].set_xlabel('Removed outlier')\n",
    "ax[1].invert_yaxis()\n",
    "\n",
    "ax[0].set_title('Iterative outlier removal results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbd61a3-d3fd-4ddf-8fc0-e14529722be6",
   "metadata": {},
   "source": [
    "### Old"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c1020b1b-f871-4680-a960-9b152e09c960",
   "metadata": {},
   "source": [
    "train_stdev = remainder[train_col].std()\n",
    "train_avg = remainder[train_col].mean()\n",
    "test_stdev = remainder[test_col].std()\n",
    "test_avg = remainder[test_col].mean()\n",
    "potential_outliers = remainder[\n",
    "    (remainder[train_col] < train_avg-train_stdev)& # low RMSECV\n",
    "    (remainder[test_col] > test_avg+test_stdev) # high RMSEP\n",
    "]\n",
    "if len(potential_outliers)==0:\n",
    "    to_continue = False"
   ]
  },
  {
   "cell_type": "raw",
   "id": "afe046e9-c419-48b3-a683-c19d6b7d03bf",
   "metadata": {},
   "source": [
    "for fold in meta.Fold.unique():\n",
    "    # remove sample\n",
    "    temp_meta = meta[meta.Fold!=fold].copy()\n",
    "    # prep data\n",
    "    X_train = np.array(spectra[temp_meta.pkey].T)\n",
    "    y_train = list(temp_meta[variable].values)\n",
    "    y_test = var_dict[fold_dict[fold]]\n",
    "    # make model\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "811c3f90-3476-4225-bd84-22c7bc22d153",
   "metadata": {},
   "source": [
    "    component_range = np.arange(start=2, stop=max_components+1, step=1)\n",
    "\n",
    "    cv_dict = {}\n",
    "    for n_components in tqdm(component_range, desc='component value'):\n",
    "        # define model\n",
    "        model = PLSRegression(n_components = n_components, scale=False)\n",
    "        # run CV and get RMSE\n",
    "        temp_rmsecv = Model.run_CV(self, model)\n",
    "        # add results to dictionary\n",
    "        cv_dict[temp_rmsecv] = n_components\n",
    "        \n",
    "    rmsecv = get_first_local_minimum(list(cv_dict.keys()))\n",
    "    component = cv_dict[rmsecv]\n",
    "    model = PLSRegression(n_components = component, scale=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
